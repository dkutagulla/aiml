{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Notes",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bMOBpRPHSiarG-Av0_lMIVQNttwj0xQ0",
      "authorship_tag": "ABX9TyPTWtdF5zTdunA7W+G4xqWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkutagulla/aiml/blob/AI_ML_ForCoders/Machine_Learning_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C1BjYg-3S4v"
      },
      "source": [
        "# Notes and code\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tJ4m7FPJyxl"
      },
      "source": [
        "My notes of ML book I am reading **AI and Machine Learning for Coders**\r\n",
        "\r\n",
        "Notes using TensorFlow API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRsh-K-f3wp7"
      },
      "source": [
        "# TensorFlow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KakY95S83AVu",
        "outputId": "f03c6132-74dd-431c-e526-faa6767af635"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzjbXtrf5FMu"
      },
      "source": [
        "# Model \r\n",
        "1. relationship that takes input(s) and produces output(s)\r\n",
        "2. contains (set of)  parameters that transform input to output.\r\n",
        "idea is to have a set of parameters that can apply to all input(s) values \r\n",
        "Neurons are the individual building blocks of the models\r\n",
        "\r\n",
        "   \r\n",
        "# Simple example\r\n",
        "Determine relation (model)  between x and y based on input data\r\n",
        "1. build the model using a sample of x input values and y output values and use it to predict a value of y given a x value.\r\n",
        "2. have tf output parameters of the model.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGoFYvgDQ2PC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSWoAj6t4Aqg"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "\r\n",
        "first_layer = Dense( \r\n",
        "    units=1, # how many neurons \r\n",
        "    input_shape=[1] # how many inputs to neuron ;\r\n",
        "    # ONLY specified for first layer\r\n",
        "    )\r\n",
        "\r\n",
        "# model has array of layers inside the Sequential container \r\n",
        "model = Sequential( \r\n",
        "                   [ # layer description  ; array of layers\r\n",
        "                       first_layer\r\n",
        "                   ]  \r\n",
        "    )\r\n",
        "\r\n",
        "# setup training method sgd = stochastic gradient descent\r\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\r\n",
        "\r\n",
        "# example data to develop model\r\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\r\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\r\n",
        "\r\n",
        "model.fit(xs, ys, epochs=500) # train model on input data for 500 trials\r\n",
        "\r\n",
        "print(\"Model predicted value for x=10 : {}\" .format ( model.predict([10.0]))) # use model to predict value\r\n",
        "\r\n",
        "# output how model looks like\r\n",
        "print(\"Model parameters: {}\".format(\r\n",
        "                                    first_layer.get_weights()\r\n",
        "                                    ))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjOOe1GwK8hu"
      },
      "source": [
        "# More Complicated Neural Network\r\n",
        "## ML for image classification\r\n",
        "\r\n",
        "\r\n",
        "### Goal \r\n",
        "Train the computer to 'see' twhat type of apparel a given picture shows : e.g. shoe, dress, ankle boot etc) \r\n",
        "\r\n",
        "###Input \r\n",
        "FashionMNIST: DB of B/W images of apparel. \r\n",
        "\r\n",
        "### Data structure : Neural network (NN)\r\n",
        "3 layer NN \r\n",
        "* 0th layer : flattened input layer ( in order to be able to feed values to neurons). \r\n",
        "Layer consist of series of numbers \r\n",
        "2D Image data converted into a 1D series of numbers\r\n",
        "* 1st layer of of 128 neurons\r\n",
        "* 2nd layer of 10 output neurons ( since there are 10 classes in image data set) \r\n",
        "128 is a hyperparameter : it specifies how many neurons are present. It is not model parameter but a parameter that determines the structure of the Neural network \r\n",
        "Each layer defines an Activation function. This defines the functionality of each neuron in that lyaer) \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckVtmEo_o3k2"
      },
      "source": [
        "# hgmodel = keras.Sequential([\r\n",
        "#                          keras.layers.Flatten(input_shape=(28, 28)),    \r\n",
        "#                          keras.layers.Dense(128, activation=tf.nn.relu),    \r\n",
        "#                          keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "#                          ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRPF3EzRq1Ms"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "data = tf.keras.datasets.fashion_mnist\r\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\r\n",
        "\r\n",
        "training_images  = training_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential(\r\n",
        "         [\r\n",
        "           tf.keras.layers.Flatten(input_shape=(28, 28)), # image flattening layer                                    \r\n",
        "           ## the neural network\r\n",
        "           tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "           tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "         ]\r\n",
        "    )\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer='adam',\r\n",
        "    loss='sparse_categorical_crossentropy',\r\n",
        "    metrics=['accuracy']\r\n",
        "    )\r\n",
        "\r\n",
        "model.fit(training_images, training_labels, epochs=5)\r\n",
        "\r\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDFAs9QCmrYk"
      },
      "source": [
        "\r\n",
        "# Convolutional Neural Networks\r\n",
        "\r\n",
        "To improve model training turnaround time, the number of parameters in model needs to reduced without losing important parameters information useful to train model. \r\n",
        "\r\n",
        "Convolution and Pooling are two common operations applied in sequence to extract salient features in the model and reduce the input data size while preserving the said features contained in the input data.\r\n",
        "\r\n",
        "##  Convolution \r\n",
        "Convolution is used to emphasize features in am image.\r\n",
        "\r\n",
        "Convolution is implemented as a matrix of coefficients. this matrix is called a filter (a.k.a kernel) . The filter is 'superposed' on top of the image ( which is itself a 28 x 28 matrix) and slid across it while ensuring that the filter matrix does not go out out the image boundary. As the filter matrix is slid across the image, image pixel values are multiplied by filter values and the product is stored into another image matrix. the resultant image matrix is a Convolved version of original image.\r\n",
        "\r\n",
        "In ML Convolution is modelled as a neural network. it consists of neurons. Each neuron performs a  multiplication ( convolution) on each pixel.  The result is fed forward to the output layers where the loss value  ( via loss function) is computed. The error is computed from this loss value and used to compute the scaling factors for filter matrix coefficients. These cofficients are the weights and bias values for that neuron. The cofficients are scaled by the scaling factors and fed back to neuron which computes another convolution value. This process is repeated for each neuron AND repeated as whole until the convolution layer achieves a small loss. \r\n",
        "\r\n",
        "## Pooling\r\n",
        "Pooling is used to reduce image  (input data)  size while keeping features. \r\n",
        "Pooling is typically applied after convolution in order to extract features from convoluted image.  This operation reduces the size of input data and thus improves model performace and accuracy. \r\n",
        "\r\n",
        "In ML, a Pooling layer is used to reduce the number of wieghts and bias values ( effectively reducing the # of neurons). this helps reduce the size of network and thusimprove computation time improving performance. It also helps to enhance accurace of model. lesser nrurons can mean less noise which prents the model from diverging.  \r\n",
        "\r\n",
        "\r\n",
        "# More information: \r\n",
        "1. https://homepages.inf.ed.ac.uk/rbf/HIPR2/convolve.htm\r\n",
        "2. https://blog.francium.tech/machine-learning-convolution-for-image-processing-42623c8dbec0\r\n",
        "\r\n",
        "\r\n",
        "Original NN code: \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0QXeH9q0uFt"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "data = tf.keras.datasets.fashion_mnist\r\n",
        "\r\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\r\n",
        "\r\n",
        "training_images = training_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "# the NN definition\r\n",
        "\r\n",
        "# First layer Flatten is only input layer does not have any neurons \r\n",
        "# The 2nd (hidden) and 3rd (output)  layer have 128 and 10 neurons \r\n",
        "# and are densely (Dense)  interconnected.\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "    ])\r\n",
        "\r\n",
        "# specify how to train the NN \r\n",
        "model.compile(optimizer='adam',\r\n",
        "       loss='sparse_categorical_crossentropy',\r\n",
        "       metrics=['accuracy'])\r\n",
        "\r\n",
        "# do the training\r\n",
        "model.fit(training_images, training_labels, epochs=5)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0uL1mDs0vMn"
      },
      "source": [
        "NN Code with Covolution and Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FINZ8Bnis4Ar"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "data = tf.keras.datasets.fashion_mnist\r\n",
        "\r\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\r\n",
        "\r\n",
        "# massage and normalize training data to be 3D \r\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\r\n",
        "training_images = training_images / 255.0\r\n",
        "\r\n",
        "# massage and normalize test data to be 3D \r\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential([\r\n",
        "# convolution and pooling layers                                    \r\n",
        "   tf.keras.layers.Conv2D(64, \r\n",
        "                          (3, 3), \r\n",
        "                          activation='relu', \r\n",
        "                          input_shape=(28, 28, 1)),\r\n",
        "   tf.keras.layers.MaxPooling2D(2, 2),      \r\n",
        "   tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),      \r\n",
        "   tf.keras.layers.MaxPooling2D(2,2),      \r\n",
        "# NN  input layer\r\n",
        "   tf.keras.layers.Flatten(),      \r\n",
        "# NN\r\n",
        "   tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "   tf.keras.layers.Dense(10, activation=tf.nn.softmax)    \r\n",
        "   ])\r\n",
        "\r\n",
        "model.compile(optimizer='adam',       \r\n",
        "              loss='sparse_categorical_crossentropy',       \r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(training_images, training_labels, epochs=50)\r\n",
        "\r\n",
        "model.evaluate(test_images, test_labels)\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joNfYLbzsySz"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFAMwm11D5O1"
      },
      "source": [
        "# More Complex CNN\r\n",
        "\r\n",
        "In this example we will build a CNN that will classify images into one of 2 catehgories : Horsew and Humans.\r\n",
        "\r\n",
        "## Prerequisites\r\n",
        "### Connecting Google Drive to Colab\r\n",
        "Useful to know how we connect our Gdrive to colab so that we can save /load our files from there.  Below liunk has useful information on this:\r\n",
        "https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/\r\n",
        "\r\n",
        "### Saving/Restoring models \r\n",
        "In the code below I have setup logic to save the model data to my gdrive area. In case the training is interrupted I can reload the model and resume from where I left off thus saving valuable time.\r\n",
        "\r\n",
        "Below links provide useful information on model saving and restoring:\r\n",
        "\r\n",
        "https://www.tensorflow.org/guide/keras/save_and_serialize\r\n",
        "\r\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load\r\n",
        "\r\n",
        "SavedModel format\r\n",
        "https://www.tensorflow.org/guide/saved_model\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf6eDyW2G0bv",
        "outputId": "5446b34b-2be2-4dca-ec04-127e57e0ce3a"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive');\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8-kzyvm-NwB"
      },
      "source": [
        "### Download image data\r\n",
        "Example shows also how to download compressed data from URL and extract it into specific directory.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHaDR0FTE9v6"
      },
      "source": [
        "import urllib.request\r\n",
        "import zipfile\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\r\n",
        "file_name = \"horse-or-human.zip\"\r\n",
        "training_dir = '/content/gdrive/MyDrive/data/horse-or-human/training/'\r\n",
        "urllib.request.urlretrieve(url, file_name)\r\n",
        "\r\n",
        "zip_ref = zipfile.ZipFile(file_name, 'r')\r\n",
        "zip_ref.extractall(training_dir)\r\n",
        "zip_ref.close()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLKhpsH1NXNT"
      },
      "source": [
        "\r\n",
        "### Helpers\r\n",
        "1. Create a model. This will be helpful when we want to restore a saved model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPc-BP61678E"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "def createModel():\r\n",
        "  \r\n",
        "  model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu' , input_shape=(300, 300, 3)),\r\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "  ])\r\n",
        "\r\n",
        "  model.compile(loss='binary_crossentropy',\r\n",
        "        optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\r\n",
        "        metrics=['accuracy'])\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlcciHCH9ZjZ"
      },
      "source": [
        "### Create Model input data pipeline \r\n",
        "Automatically assign labels to images\r\n",
        "This also setup a stream \r\n",
        "1. `ImageDataGenerator`  from keras is used to assign labels to images.\r\n",
        "2. `ImageDataGenerator` also sets up input data pipeline to our training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cdka-KL9kkd",
        "outputId": "0a8aecc9-9d62-449d-f41b-a383849e2ec0"
      },
      "source": [
        "# Automatically assign labels to images\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "# All images will be rescaled by 1./255\r\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "  training_dir,\r\n",
        "  target_size=(300, 300),\r\n",
        "  class_mode='binary'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VccAD3b9lly"
      },
      "source": [
        "### Setup Callbacks : Save Model, Stop Training\r\n",
        "1. save the model every 5 epochs\r\n",
        "2. Stop training once desired accuracy is reached\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMXeAeF2NRhw",
        "outputId": "f1c86d2b-9e22-44c8-8d0b-cc543dbe4e9f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "\r\n",
        "########################\r\n",
        "# CallBacks\r\n",
        "#\r\n",
        "# 1. save model after every 5 epochs;  believe default batch size is 32 \r\n",
        "checkpoint_path = \"/content/gdrive/MyDrive/data/hoh_model/training_1/cp-{epoch:04d}.ckpt\"\r\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\r\n",
        "batch_size =32;\r\n",
        "saveTheModel = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                                 save_weights_only=True,\r\n",
        "                                                 save_freq = 5 * batch_size,\r\n",
        "                                                 verbose=1)\r\n",
        "# 2. stop training when desired accuracy is reached\r\n",
        "class stopTraining(tf.keras.callbacks.Callback):\r\n",
        "  def on_epoch_end(self, epoch, logs={}):\r\n",
        "    if(logs.get('accuracy')>0.98):\r\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "stopTrainingCBObj = stopTraining();\r\n",
        "##################\r\n",
        "\r\n",
        "# register callbacks\r\n",
        "model = createModel();\r\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 298, 298, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 149, 149, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 33, 33, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,704,097\n",
            "Trainable params: 1,704,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVHtXLBq_Ten"
      },
      "source": [
        "### Train the model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVe6-Ia3_u8h",
        "outputId": "95714ab2-71ad-46b8-8c54-ab3a78e3030c"
      },
      "source": [
        "# train the Model\r\n",
        "history = model.fit(\r\n",
        "  train_generator,\r\n",
        "  epochs=15,\r\n",
        "  callbacks=[saveTheModel, stopTrainingCBObj]\r\n",
        ")\r\n",
        "\r\n",
        "# at end of training save in SavedModel format\r\n",
        "model.save('/content/gdrive/MyDrive/data/hoh_saved_model/my_model') \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 0.7315 - accuracy: 0.6006\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 0.2651 - accuracy: 0.9070\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 89s 3s/step - loss: 0.0880 - accuracy: 0.9706\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 88s 3s/step - loss: 0.0783 - accuracy: 0.9704\n",
            "Epoch 5/15\n",
            "28/33 [========================>.....] - ETA: 13s - loss: 0.1393 - accuracy: 0.9886\n",
            "Epoch 00005: saving model to /content/gdrive/MyDrive/data/hoh_model/training_1/cp-0005.ckpt\n",
            "33/33 [==============================] - 88s 3s/step - loss: 0.2443 - accuracy: 0.9830\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 88s 3s/step - loss: 0.0641 - accuracy: 0.9740\n",
            "\n",
            "Reached 95% accuracy so cancelling training!\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/data/hoh_saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5nf-xyzYNIz"
      },
      "source": [
        "## Loading a saved model\r\n",
        "if trainimng is interrupted, a saved model can reloaded and training resumed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvBBie4k5LDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5586fba-618a-4f85-efd1-3c592cf85bc1"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\r\n",
        "\r\n",
        "# Create a new model instance\r\n",
        "model = createModel()\r\n",
        "\r\n",
        "# Load the previously saved weights\r\n",
        "model.load_weights(latest)\r\n",
        "\r\n",
        "model.evaluate()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 298, 298, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 149, 149, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 33, 33, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,704,097\n",
            "Trainable params: 1,704,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1d2211d29a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 964\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    965\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
          ]
        }
      ]
    }
  ]
}